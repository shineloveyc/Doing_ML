{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bert_test.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPSJgiPbeJWONCH0i+sQiRD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shineloveyc/Doing_ML/blob/master/Bert_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHv5hvpEghRR",
        "colab_type": "text"
      },
      "source": [
        "# Bert tutorial\n",
        "https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Day7bnQYgTFO",
        "colab_type": "code",
        "outputId": "6031b384-257c-412b-d2ce-57b1a636420c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "#the benchmark model for many NLP task\n",
        "!pip install pytorch-pretrained-bert"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-pretrained-bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 18.4MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20kB 1.9MB/s eta 0:00:01\r\u001b[K     |████████                        | 30kB 2.5MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40kB 1.8MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61kB 2.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92kB 3.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 2.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.21.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.11.15)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.17.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.28.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2019.11.28)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (1.14.15)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->pytorch-pretrained-bert) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->pytorch-pretrained-bert) (2.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.15.0,>=1.14.15->boto3->pytorch-pretrained-bert) (1.12.0)\n",
            "Installing collected packages: pytorch-pretrained-bert\n",
            "Successfully installed pytorch-pretrained-bert-0.6.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Na6Em8F4gpyO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
        "\n",
        "import logging\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thBEsgqDhSqB",
        "colab_type": "code",
        "outputId": "baee87df-7a99-4a2d-c4c1-4374105579fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#load the pre-trained model tokenizer (vocabulary)\n",
        "#12-layer, 768-hidden, 12-heads, 110M parameters.Trained on lower-cased English text.\n",
        "#https://huggingface.co/transformers/pretrained_models.html\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 6289608.58B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lU6geyilp5kG",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdU2SrtQiE1K",
        "colab_type": "text"
      },
      "source": [
        "Because BERT is a pretrained model that expects input data in a specific format, we will need:\n",
        "\n",
        "* special tokens to mark the beginning ([CLS]) and separation/end of sentences ([SEP])\n",
        "* tokens that conforms with the fixed vocabulary used in BERT\n",
        "token IDs from BERT’s tokenizer\n",
        "* mask IDs to indicate which elements in the sequence are tokens and which are padding elements\n",
        "*segment IDs used to distinguish different sentences\n",
        "positional embeddings used to show token position within the sequence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7R6J0tjhkhU",
        "colab_type": "code",
        "outputId": "06e2e787-97e6-42a2-8ba7-d63224211eec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#test the tokenizer\n",
        "text = \"Here is the sentence I want to embedding for.\"\n",
        "\n",
        "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
        "\n",
        "tokenized_text = tokenizer.tokenize(marked_text)\n",
        "\n",
        "print(tokenized_text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[CLS]', 'here', 'is', 'the', 'sentence', 'i', 'want', 'to', 'em', '##bed', '##ding', 'for', '.', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPBHERPqmVmz",
        "colab_type": "text"
      },
      "source": [
        "Why does it look this way? This is because the BERT tokenizer was created with a WordPiece model. This model greedily creates a fixed-size vocabulary of individual characters, subwords, and words that best fits our language data. Since the vocabulary limit size of our BERT tokenizer model is 30,000, the WordPiece model generated a vocabulary that contains all English characters plus the ~30,000 most common words and subwords found in the English language corpus the model is trained on. This vocabulary contains four things:\n",
        "\n",
        "* Whole words\n",
        "* Subwords occuring at the front of a word or in isolation (“em” as in “embeddings” is assigned the same vector as the standalone sequence of characters “em” as in “go get em” )\n",
        "* Subwords not at the front of a word, which are preceded by ‘##’ to denote this case\n",
        "* Individual characters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpIJKarUnXv0",
        "colab_type": "text"
      },
      "source": [
        "To tokenize a word under this model, the tokenizer first checks if the whole word is in the vocabulary. If not, it tries to break the word into the largest possible subwords contained in the vocabulary, and as a last resort will decompose the word into individual characters. Note that because of this, we can always represent a word as, at the very least, the collection of its individual characters.\n",
        "\n",
        "As a result, rather than assigning out of vocabulary words to a catch-all token like ‘OOV’ or ‘UNK,’ words that are not in the vocabulary are decomposed into subword and character tokens that we can then generate embeddings for."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5tqXcVwnNRI",
        "colab_type": "code",
        "outputId": "a4143937-59d8-4a4b-fb87-37ecb11cb56d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "#print the bert vocab\n",
        "#Tokens beginning with two hashes are subwords or individual characters.\n",
        "list(tokenizer.vocab.keys())[5000:5020]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['knight',\n",
              " 'lap',\n",
              " 'survey',\n",
              " 'ma',\n",
              " '##ow',\n",
              " 'noise',\n",
              " 'billy',\n",
              " '##ium',\n",
              " 'shooting',\n",
              " 'guide',\n",
              " 'bedroom',\n",
              " 'priest',\n",
              " 'resistance',\n",
              " 'motor',\n",
              " 'homes',\n",
              " 'sounded',\n",
              " 'giant',\n",
              " '##mer',\n",
              " '150',\n",
              " 'scenes']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQYHR6o9pBsR",
        "colab_type": "code",
        "outputId": "8b0de2b7-ef43-49cf-841b-9ed4b57411b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "#After breaking the text into tokens, we then have to convert the sentence from a list of strings to a list of vocabulary indeces.\n",
        "#map the token strings to their vocabulary indeces\n",
        "\n",
        "# Define a new example sentence with multiple meanings of the word \"bank\"\n",
        "text = \"After stealing money from the bank vault, the bank robber was seen \" \\\n",
        "       \"fishing on the Mississippi river bank.\"\n",
        "\n",
        "# Add the special tokens.\n",
        "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
        "\n",
        "# Split the sentence into tokens.\n",
        "tokenized_text = tokenizer.tokenize(marked_text)\n",
        "\n",
        "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "\n",
        "for tup in zip(tokenized_text, indexed_tokens):\n",
        "     print('{:<12} {:>6,}'.format(tup[0], tup[1]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS]           101\n",
            "after         2,044\n",
            "stealing     11,065\n",
            "money         2,769\n",
            "from          2,013\n",
            "the           1,996\n",
            "bank          2,924\n",
            "vault        11,632\n",
            ",             1,010\n",
            "the           1,996\n",
            "bank          2,924\n",
            "robber       27,307\n",
            "was           2,001\n",
            "seen          2,464\n",
            "fishing       5,645\n",
            "on            2,006\n",
            "the           1,996\n",
            "mississippi   5,900\n",
            "river         2,314\n",
            "bank          2,924\n",
            ".             1,012\n",
            "[SEP]           102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hvCKm53p1vU",
        "colab_type": "text"
      },
      "source": [
        "### Segment ID"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oEhEy63p3Mo",
        "colab_type": "code",
        "outputId": "e11e8d77-18f2-41a5-dbdd-d2ab538079f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# use 1s and 0s to distinguish between the two sentences. if all tokens from first setences, then 0, from 2nd, then 1\n",
        "#since the example is single sentence input, so all 1\n",
        "segments_ids = [1] * len(tokenized_text)\n",
        "\n",
        "print(segments_ids)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G96X6WKA5d2n",
        "colab_type": "text"
      },
      "source": [
        "## Extracting Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43IC-h9T5ZRn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#covert our data to tensor by using torch and call the BERT model\n",
        "#convert input to PyTorch tensors\n",
        "tokens_tensor = torch.tensor([indexed_tokens])\n",
        "\n",
        "#convert segment to Pytorch tensors\n",
        "segments_tensor = torch.tensor(segments_ids)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GhTUQec7TME",
        "colab_type": "code",
        "outputId": "c4857c43-4de1-45ed-cc2a-5c96e2f2d777",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#load pre-trained model(weights)==>12 layers\n",
        "model = BertModel.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 407873900/407873900 [00:06<00:00, 67834574.41B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qt77f3-K7o5E",
        "colab_type": "code",
        "outputId": "f0194265-265c-4591-aa23-79777d6be36c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#put the model in 'evaluation' mode, meaning feed-forward operations\n",
        "model.eval()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): BertLayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diLpGU0n8Ale",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#predict hidden states features for each layer\n",
        "with torch.no_grad():\n",
        "  encoded_layers, _ = model(tokens_tensor, segments_tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyVU4vkY8xWR",
        "colab_type": "text"
      },
      "source": [
        "The full set of hidden states for this model, stored in the object encoded_layers, is a little dizzying. This object has four dimensions, in the following order:\n",
        "\n",
        "* The layer number (12 layers)\n",
        "* The batch number (1 sentence)\n",
        "* The word / token number (22 tokens in our sentence)\n",
        "* The hidden unit / feature number (768 features)\n",
        "That’s 202,752 unique values just to represent our one sentence! 12*22*768\n",
        "\n",
        "The second dimension, the batch size, is used when submitting multiple sentences to the model at once; here, though, we just have one example sentence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPK98ACsk0hZ",
        "colab_type": "text"
      },
      "source": [
        "![alt text](http://jalammar.github.io/images/bert-contexualized-embeddings.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pmuj_X-z8i1n",
        "colab_type": "code",
        "outputId": "44cc98e3-d0e6-40c6-a72b-8420eecdd17b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print('Number of layers:', len(encoded_layers))\n",
        "layer_i = 0\n",
        "\n",
        "print(\"Number of batches:\", len(encoded_layers[layer_i]))\n",
        "batch_i = 0\n",
        "\n",
        "print(\"number of tokens:\", len(encoded_layers[layer_i][batch_i]))\n",
        "token_i = 0\n",
        "\n",
        "print(\"Number of hidden units:\", len(encoded_layers[layer_i][batch_i][token_i]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of layers: 12\n",
            "Number of batches: 1\n",
            "number of tokens: 22\n",
            "Number of hidden units: 768\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMCWQBx9_Ceq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# check the 5th token in our setence, select its feature values from layer 5\n",
        "token_i = 5,\n",
        "layer = 5\n",
        "\n",
        "vec = encoded_layers[layer_i][batch_i][token_i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Xl4mJg2_Y9f",
        "colab_type": "code",
        "outputId": "80976d42-958b-45e4-e877-f5c3a6fd5837",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        }
      },
      "source": [
        "#plot the feature values as a histogram to show the distribution==> [-2, 2]\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.hist(vec, bins = 200)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlAAAAI/CAYAAAC4QOfKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAgAY+n/gnn+qpaZFegAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JwTF3B0_3tM",
        "colab_type": "code",
        "outputId": "ed9d63b4-5d51-454c-c16c-cc1555804af9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# encoded layer is a python list\n",
        "print(' type of encoded layer:', type(encoded_layers))\n",
        "\n",
        "#each layers in the list is a torch tensor\n",
        "print(\"tensore shape for each layer:\", encoded_layers[0].size())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " type of encoded layer: <class 'list'>\n",
            "tensore shape for each layer: torch.Size([1, 22, 768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyUpNzfSAhQD",
        "colab_type": "code",
        "outputId": "5b0d7cd3-8c6b-460e-af6b-bf6f77d2f87b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#combine the 12 layers to make one big tensore\n",
        "token_embeddings = torch.stack(encoded_layers, dim = 0)\n",
        "\n",
        "token_embeddings.size()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([12, 1, 22, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vr2TNvPMA2nQ",
        "colab_type": "code",
        "outputId": "4f538b6e-aee6-4d69-c58e-7c8e4973c3bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#get rid of batch dimension as there is only one setence\n",
        "token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
        "\n",
        "token_embeddings.size()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([12, 22, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1snNbpBBWY1",
        "colab_type": "code",
        "outputId": "94266825-7898-4600-8f0d-012adc9b85b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#swap dimensions 0 and 1\n",
        "\n",
        "token_embeddings = token_embeddings.permute(1, 0, 2)\n",
        "\n",
        "token_embeddings.size()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([22, 12, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvjAFpUiBtn8",
        "colab_type": "text"
      },
      "source": [
        "### Create word and setence vectors from hidden states"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CctzmPhfBr8Q",
        "colab_type": "code",
        "outputId": "b2c1fc6f-fbda-4f5c-ba2b-c8492ad9f221",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#store the token vectors, with shape [22* 3072] 3072 = 4 * 768\n",
        "token_vecs_cat = []\n",
        "\n",
        "#for each token in the setence...\n",
        "for token in token_embeddings:\n",
        "  #token is a [12* 768] tensore\n",
        "  # Concatenate the vectors (that is, append them together) from the last four layers.\n",
        "  # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
        "\n",
        "  cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim = 0)\n",
        "  token_vecs_cat.append(cat_vec)\n",
        "  #used the 'cat_vec' to represent 'token'\n",
        "\n",
        "print( 'Shape is %d * %d' % (len(token_vecs_cat), len(token_vecs_cat[0])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape is 22 * 3072\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMAY9cmjGhfx",
        "colab_type": "code",
        "outputId": "66a83c4a-0540-4bb2-b6e7-67f097940af3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#store the token vectors with shape [22*768]\n",
        "\n",
        "token_vecs_sum = []\n",
        "\n",
        "for token in token_embeddings:\n",
        "  #sum vector from the last four layers\n",
        "  sum_vec= torch.sum(token[-4:], dim = 0)\n",
        "\n",
        "  #use 'sum_vec' to represent 'token\n",
        "  token_vecs_sum.append(sum_vec)\n",
        "\n",
        "print('Shape is %d * %d' % (len(token_vecs_sum), len(token_vecs_sum[0])))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape is 22 * 768\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7nWKoUUHiVO",
        "colab_type": "code",
        "outputId": "78651b46-45d9-4baa-a1bf-fcfcbc8b6d22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#get sentence vectors by average the second to last hidden layers of each token producing a single 768 vectors\n",
        "\n",
        "token_vecs  = encoded_layers[11][0]\n",
        "\n",
        "token_vecs.size()\n",
        "\n",
        "setence_embedding = torch.mean(token_vecs, dim = 0)\n",
        "\n",
        "print(\"Our final sentence embedding vector of shape:\", setence_embedding.size(0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Our final sentence embedding vector of shape: 768\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kKuU53Uf6s2",
        "colab_type": "text"
      },
      "source": [
        "#### Confirm contextually dependent vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wv7H7Almfuwn",
        "colab_type": "code",
        "outputId": "27c71347-7d8b-4871-d8e3-33250f703096",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "# find index of three 'bank' in the example setence\n",
        "for i, token_str in enumerate(tokenized_text):\n",
        "  print( i , token_str)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 [CLS]\n",
            "1 after\n",
            "2 stealing\n",
            "3 money\n",
            "4 from\n",
            "5 the\n",
            "6 bank\n",
            "7 vault\n",
            "8 ,\n",
            "9 the\n",
            "10 bank\n",
            "11 robber\n",
            "12 was\n",
            "13 seen\n",
            "14 fishing\n",
            "15 on\n",
            "16 the\n",
            "17 mississippi\n",
            "18 river\n",
            "19 bank\n",
            "20 .\n",
            "21 [SEP]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_vcGPGggZA6",
        "colab_type": "code",
        "outputId": "1f937008-b36d-4096-973e-c4d2ca1ad3ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "#use word vectors by summing the last four layers and compare the 'bank'\n",
        "#bank index 6, 10, 19\n",
        " print( 'First 5 vector values for each instance of \"bank\"')\n",
        " print('')\n",
        " print(\"bank vault:\", str(token_vecs_sum[6][:5]))\n",
        " print('bank robber:', str(token_vecs_sum[10][:5]))\n",
        " print('river bank:', str(token_vecs_sum[19][:5]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First 5 vector values for each instance of \"bank\"\n",
            "\n",
            "bank vault: tensor([ 2.1319, -2.1413, -1.6260,  0.8638,  3.3173])\n",
            "bank robber: tensor([ 1.1868, -1.5298, -1.3770,  1.0648,  3.1446])\n",
            "river bank: tensor([ 1.1295, -1.4725, -0.7296, -0.0901,  2.4970])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBDbGLvshOss",
        "colab_type": "code",
        "outputId": "9f766665-4c45-467c-b247-6278ae408fa6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#calculate the cosine similarity to do more precise comparision\n",
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "#calculate the cosine distance between bank robber and river bank\n",
        "diff_bank = 1- cosine(token_vecs_sum[10], token_vecs_sum[19])\n",
        "\n",
        "same_bank = 1- cosine(token_vecs_sum[6], token_vecs_sum[10])\n",
        "\n",
        "print(\"vector similarity for *similar* meanings: %.2f\" %same_bank)\n",
        "print(\"vector similarity for *difference* meanings: %.2f\" %diff_bank)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vector similarity for *similar* meanings: 0.95\n",
            "vector similarity for *difference* meanings: 0.68\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xG4YxTaah1Pk",
        "colab_type": "code",
        "outputId": "f7080bb9-247c-467a-c2dd-e273c172ee62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "token_vecs_sum[19].size()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIU4QVILjPrP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}