{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch_NN_basic_function.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPX9v3PmMmIRMtWlkl83PMw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "418872eb46a94ef8a429fd872ffb9a6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0c6853a7ba344a40a2fb2f791cfb2135",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0e0184261fc54daba9212825585fd07c",
              "IPY_MODEL_17db3148179348d5b7d481384ad6c81a"
            ]
          }
        },
        "0c6853a7ba344a40a2fb2f791cfb2135": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0e0184261fc54daba9212825585fd07c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1d30a1fdef974f04bd520e38a89a6942",
            "_dom_classes": [],
            "description": "training routine",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_87354c46c0b3454693e7ee77f8901e5c"
          }
        },
        "17db3148179348d5b7d481384ad6c81a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8336f5ef3e554cadb54b1a0987384f71",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "  0% 0/100 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d9cab2e08851458c8bb706cd3e7fd9e6"
          }
        },
        "1d30a1fdef974f04bd520e38a89a6942": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "87354c46c0b3454693e7ee77f8901e5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8336f5ef3e554cadb54b1a0987384f71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d9cab2e08851458c8bb706cd3e7fd9e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f2c09ea5341f48fb9b58c71b830aa353": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_93efb731465c4e5ba64e337553efc119",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_66b575da0248479db5c08096657639e4",
              "IPY_MODEL_ed6ef05a4b4d48249254465a816aefba"
            ]
          }
        },
        "93efb731465c4e5ba64e337553efc119": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "66b575da0248479db5c08096657639e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f459c742f6bd49648653ec6a3fc62191",
            "_dom_classes": [],
            "description": "split=train",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 306,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b3a3447c9a904c17a667759c599685d7"
          }
        },
        "ed6ef05a4b4d48249254465a816aefba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e22887f69a8c47f8a45d71ecde709d23",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "  0% 0/306 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_aca1b5af3dbe4291a1869b3b7e6b4578"
          }
        },
        "f459c742f6bd49648653ec6a3fc62191": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b3a3447c9a904c17a667759c599685d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e22887f69a8c47f8a45d71ecde709d23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "aca1b5af3dbe4291a1869b3b7e6b4578": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5769796678534953b52f264f60be8da2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_de7fc6f0a3124e19b26c7ae0ec35e2b7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c16d180185684caa848c35599aed55cd",
              "IPY_MODEL_e16d2e1e09524fd1a92615c63bed0833"
            ]
          }
        },
        "de7fc6f0a3124e19b26c7ae0ec35e2b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c16d180185684caa848c35599aed55cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5da9e1df844b4b55a53379e8d89b09b2",
            "_dom_classes": [],
            "description": "split=val",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 65,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6c3f4fc1cc7049a9a715a65076521b64"
          }
        },
        "e16d2e1e09524fd1a92615c63bed0833": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_313023f86b5640408875adf351084899",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "  0% 0/65 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7c29ff0c2bab4193bdb6793dcafc4752"
          }
        },
        "5da9e1df844b4b55a53379e8d89b09b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6c3f4fc1cc7049a9a715a65076521b64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "313023f86b5640408875adf351084899": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7c29ff0c2bab4193bdb6793dcafc4752": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shineloveyc/Doing_ML/blob/master/PyTorch_NN_basic_function.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1IQQl6WQYB6",
        "colab_type": "text"
      },
      "source": [
        "# Activation Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJCRwA2bhZX3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#implement a basic perceptron in Pytorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import os\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import collections\n",
        "import string\n",
        "import json\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import re\n",
        "from argparse import Namespace\n",
        "from tqdm import tqdm_notebook"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvxxXmdGhkV6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#take a srbitary number of input, does the affine transform, applies the activation function and produc a single output\n",
        "class Perceptron(nn.Module):\n",
        "  \"\"\"a perceptron is one linear layer\"\"\"\n",
        "  def __init__(self, input_dim):\n",
        "    super(Perceptron, self).__init__()\n",
        "    self.fc1 = nn.Linear(input_dim,1)\n",
        "  \n",
        "  def forward(self, x_in):\n",
        "    \"\"\" The forward pass of the perceptron\n",
        "    Args:\n",
        "      x_in(torch.tensor): an input data tensor\n",
        "        x_in.shape should be (batch, num_features)\n",
        "      Returns:\n",
        "        the result tensor shape should be (batch, )\n",
        "      \"\"\"\n",
        "    return torch.sigmoid(self.fc1(x_in)).sequeeze()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5X1rzmw_k5Ul",
        "colab_type": "code",
        "outputId": "a474435d-cacf-43d6-fdf7-bafb9e5c465b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "#signmoid function\n",
        "\"\"\"It takes any real value and squashes it into the range between 0 and 1.\"\"\"\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = torch.arange(-5., 5., 0.1)\n",
        "y= torch.sigmoid(x)\n",
        "\n",
        "plt.plot(x.numpy(), y.numpy())\n",
        "plt.show()"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCRW6iEiYUKGLiIQJFbqISJj4/0tmGO21nq61AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBu5yeYpmxi4",
        "colab_type": "text"
      },
      "source": [
        "As you can observe from the plot, the sigmoid function saturates (i.e., produces\n",
        "extreme valued outputs) very quickly and for a majority of the inputs. This can\n",
        "become a problem because it can lead to the gradients becoming either zero or\n",
        "diverging to an overflowing floating-point value. These phenomena are also\n",
        "known as vanishing gradient problem and exploding gradient problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQAicyhpk-kM",
        "colab_type": "code",
        "outputId": "c9a2fbf4-3805-4988-9bbe-ed730124e76d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "#Tanh\n",
        "\"\"\"Notice that tanh, like the sigmoid, is also a\n",
        "“squashing” function, except that it maps the set of real values from (–∞, +∞) to\n",
        "the range [-1, +1]\"\"\"\n",
        "y_tah = torch.tanh(x)\n",
        "\n",
        "plt.plot(x.numpy(), y.numpy())\n",
        "plt.show()"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAfzklEQVR4nO3deXydZZ338c8v+54uSbolaVqaLill\na2hTGBZlKwVhXAYolEWW6ktRfAZBFh/GQccRcUQeB8VSlL3IIkzFSgVECtJCU7pvaZouSbdszb6e\n5Hr+SGBCbclpe5L7LN/36+UrOefczfkek3y5cp3rvm5zziEiIqEvyusAIiISGCp0EZEwoUIXEQkT\nKnQRkTChQhcRCRMxXj1xRkaGy8vL8+rpRURC0qpVq6qdc5mHe8yzQs/Ly6O4uNirpxcRCUlmtutI\nj2nKRUQkTKjQRUTChApdRCRMqNBFRMJEv4VuZr81s0oz23CEx83M/p+ZlZrZOjM7LfAxRUSkP/6M\n0J8AZn/G4xcD+b3/mw/8+vhjiYjI0eq30J1zy4DazzjkcuAp12MFMMTMRgUqoIiI+CcQ69DHAOV9\nblf03rfv0APNbD49o3hyc3MD8NQiIsGju9vR2O6jobWTxjYfTe0+Gts6aWrv+by53UdTexfnTc7i\n5JwhAX/+QT2xyDm3AFgAUFhYqI3YRSRoOedoaPVR1dROdVM7NU0d1DT3fDzY0sHBlk7qWno+r2/t\npK6lp7j9ucREVmp80Bb6HiCnz+3s3vtERIKSc47qpg721LWy52Ar++pb2Vffxv76NvY3tHGgoY3K\nxnY6fN2H/ffpibEMTYplaHIcmSnx5Gelkp4YS1piLGkJMZ98TE2IJSU+huT4GFITej4mxUYTFWUD\n8roCUeiLgVvN7HlgJlDvnPuH6RYRkcHU3e3YW9/KjupmdlY3U1bdzO6aFnbXtlB+sIW2zk+XdWJs\nNKOGJDAiNYHCsUMZkZZAZmo8manxZKTEMzwljuHJ8QxNiiUmOjhXfPdb6Ga2CDgXyDCzCuDfgFgA\n59yjwBJgDlAKtABfHaiwIiKHcs5R2djO5n0NbNnfSMn+RrZVNlFa2URrZ9cnxyXFRZM7LIlxGcmc\nMzGT7KGJjBmaxJghiYwZkkhaYgxmAzNyHiz9Frpzbm4/jzvgmwFLJCLyGSob2lhdXsfa8jo27G1g\n0956qps6Pnl8VHoCE7JSuGpGDhOyUjghM4VxGclkpcaHfGH3x7PdFkVE+tPd7diyv5HiXbWs3HmQ\nVTtr2VvfBkBMlJE/IpXPTcpi6ug0poxKY/LINNKTYj1O7R0VuogEDeccO6qbeXdbNcu317BiRw11\nLZ0AjExLoDBvKDflDuWUnHSmjk4nITba48TBRYUuIp5q6+xi+fYa/rqlkr+VVFJe2wrAmCGJXDBl\nBLNOGM7pecPIHpoY9lMmx0uFLiKDrqndx1ubD/D6hv28U1JFS0cXSXHRnHFCBvPPPoGz8zMYOzzZ\n65ghR4UuIoOirbOLv26pZPGavby9tZJ2XzdZqfH886ljuKBgBGecMJz4GE2hHA8VuogMGOcca8rr\neHFVBa+t3UtDm4/M1HjmzsjlkpNGMT136ICdZBOJVOgiEnCNbZ28umYvz32wm837GkiMjWb2iSP5\n0mljOOOEDKJV4gNChS4iAbOrppkn3t/Ji8UVNLX7mDo6jf/44olcdvJoUhMidznhYFGhi8hxW1Ne\nx6/eLuWNzQeIiTIuPWk0180ayyk5Q7QyZRCp0EXkmC3fXsMjb5fyXmk16YmxfPPcCVw7aywj0hK8\njhaRVOgictQ+2n2Qny3dyvvba8hMjeeeOZO5euZYUuJVKV7S//si4rdtBxr5yZ+38NaWSjJS4rjv\n0gKunpmrMzaDhApdRPpV09TOL97cxnMf7iYpLpo7LprEDWfkkawReVDRd0NEjqir2/HMil387C9b\naeno4pqZudx2Xj7DU+K9jiaHoUIXkcNaU17H919dz4Y9DfzThAz+7QsF5I9I9TqWfAYVuoh8SkuH\njweXbuWJ93eSmRLPL+eeyqUnjdLywxCgQheRTyzfXsP3Xl7H7toW5hXl8r3Zk3VCUAhRoYsI7b4u\nHnx9Kwvf20HusCQW3VLErBOGex1LjpIKXSTCbTvQyLcWrWbL/kauLRrL3XMmkxSnaghF+q6JRCjn\nHL9fWc6/Ld5ISnwMj19fyHlTRngdS46DCl0kArV2dPH9Vzfw8kcV/NOEDH5+5clkpep0/VCnQheJ\nMDuqm/n606soqWzktvPy+fZ5+drONkyo0EUiyLvbqvjmsx8RHWU88dUZnDMx0+tIEkAqdJEI4Jzj\nifd38qM/bWZCZgoLry8kZ1iS17EkwFToImHO19XND/64kWdW7OaCghE8dOUp2hUxTOm7KhLGWjp8\nfHvRat7cXMnXzhnP9y6arGt4hjEVukiYqm5q56Yni1lfUccPL5/KtbPyvI4kA0yFLhKG9ta1Mm/h\nB+ytb+XRedO5cOpIryPJIFChi4SZHdXNzFv4AQ2tnTx900xOzxvmdSQZJCp0kTCyZX8D8xZ+SLdz\nLJpfxIlj0r2OJINIhS4SJrbsb+Dqxz4gNtp4/uYiJmRp7/JIE+XPQWY228y2mlmpmd11mMdzzext\nM1ttZuvMbE7go4rIkXxc5nHRUfx+/iyVeYTqt9DNLBp4BLgYKADmmlnBIYd9H3jBOXcqcBXwq0AH\nFZHD27q/8ZOR+aL5ReRlJHsdSTzizwh9BlDqnCtzznUAzwOXH3KMA9J6P08H9gYuoogcyY7qZq5Z\n2DvNMn8W41TmEc2fQh8DlPe5XdF7X18/AOaZWQWwBPjW4b6Qmc03s2IzK66qqjqGuCLysY+XJnY7\nx7M3F6nMxb85dD/MBZ5wzmUDc4CnzewfvrZzboFzrtA5V5iZqU2BRI5VdVM78x7vWZr41I0zmJCV\n4nUkCQL+FPoeIKfP7eze+/q6CXgBwDm3HEgAMgIRUEQ+randxw2/+5C9da08fsPpWpoon/Cn0FcC\n+WY2zszi6HnTc/Ehx+wGzgMwsyn0FLrmVEQCrLOrm288+xGb9zXyq2tOY8Y4nTQk/6vfQnfO+YBb\ngaXAZnpWs2w0s/vN7LLew24HbjGztcAi4AbnnBuo0CKRyDnHPX9Yz7KSKn78xRP5/GRdLk4+za8T\ni5xzS+h5s7Pvfff1+XwTcGZgo4lIX794cxsvrqrgtvPyufL0XK/jSBAK1JuiIjKAXl29h4ff2sYV\nhdl85/x8r+NIkFKhiwS5VbsOcufL6ygaP4wf/fM0zLSfuRyeCl0kiFUcbOFrTxczOj2BX18znbgY\n/crKkWlzLpEg1dzu4+Yni2n3dfP8/NMZmhzndSQJcvrPvUgQcs5x50vrKDnQyCNXn6YTh8QvKnSR\nIPSbZWX8af0+vjd7MmdP1FnV4h8VukiQWVZSxU9f38KlJ41i/tnjvY4jIUSFLhJEymtb+Nai1Uwc\nkcpPv3KSVrTIUVGhiwSJdl8Xtz73Ed3djkfnTScpTmsW5OjoJ0YkSPz4T5tZW1HPo/Om6yIVckw0\nQhcJAn9cu5cnl+/i5n8ax+wTR3odR0KUCl3EYzuqm7nr5XVMHzuU71082es4EsJU6CIeavd18a1F\nHxEbE8Uv555KbLR+JeXYaQ5dxEM/fX0rG/Y0sODa6Ywekuh1HAlxGg6IeOSvWw7w+Hs7uH7WWC6c\nqnlzOX4qdBEPVDa08d0X1zFlVBp3z5nidRwJEyp0kUHmnOO7L62jpcPHL+eeQkJstNeRJEyo0EUG\n2VPLd7GspIp7LylgQlaq13EkjKjQRQbRtgON/HjJZj43KZN5M3UZOQksFbrIIOnwdXPb82tIiY/h\np185Wfu0SMBp2aLIIHn4rRI27Wtg4XWFZKbGex1HwpBG6CKDYPXug/z6b9u5ojCb8wtGeB1HwpQK\nXWSAtXZ0cfsLaxmVnsj/vbTA6zgSxjTlIjLAfrp0C2XVzTx380xSE2K9jiNhTCN0kQG0oqyG3/19\nJzeckccZEzK8jiNhToUuMkBaOnzc+dI6xg5P4s7Zk7yOIxFAUy4iA+TBpVvZXdvC8/OLdPUhGRQa\noYsMgOKdtTzx/k6unzWWovHDvY4jEUKFLhJgbZ1d3PHSOrKHJnLnbF2wQgaP/g4UCbCH3ihhR++q\nluR4/YrJ4NEIXSSA1lfU89i7ZVx1eo5Wtcig86vQzWy2mW01s1Izu+sIx1xhZpvMbKOZPRfYmCLB\nr7OrmztfXkdGSrz2OBdP9Pv3oJlFA48AFwAVwEozW+yc29TnmHzgbuBM59xBM8saqMAiwWrBsjI2\n72vgN9dOJz1RJxDJ4PNnhD4DKHXOlTnnOoDngcsPOeYW4BHn3EEA51xlYGOKBLftVU08/NY25kwb\nyUW6nJx4xJ9CHwOU97ld0XtfXxOBiWb2dzNbYWazD/eFzGy+mRWbWXFVVdWxJRYJMt3djrv/sJ6E\nmCh+cNlUr+NIBAvUm6IxQD5wLjAXeMzMhhx6kHNugXOu0DlXmJmZGaCnFvHWi6vK+XBHLffMmUJW\naoLXcSSC+VPoe4CcPreze+/rqwJY7JzrdM7tAEroKXiRsFbV2M5//GkzM8YN44rCnP7/gcgA8qfQ\nVwL5ZjbOzOKAq4DFhxzzKj2jc8wsg54pmLIA5hQJSve/tom2zm5+/MVpREXpCkTirX4L3TnnA24F\nlgKbgReccxvN7H4zu6z3sKVAjZltAt4G7nDO1QxUaJFg8Letlfxx7V6++bkJTMhK8TqOCOac8+SJ\nCwsLXXFxsSfPLXK8Wju6uOChd4iPiWLJbWcRHxPtdSSJEGa2yjlXeLjHdF6yyDF4+K1tVBxs5ffz\ni1TmEjR06r/IUdqyv4GF75ZxRWE2M7WTogQRFbrIUejudtzzh/WkJcZy98U6vV+Ciwpd5CgsWrmb\nj3bXce+cKQxNjvM6jsinqNBF/FTV2M4Df97CrPHD+dJph54sLeI9FbqIn368ZDNtnd386IsnYqY1\n5xJ8VOgifnh/ezWvrN7D188ZzwmZWnMuwUmFLtKPdl8X3391A7nDkvjG5yZ4HUfkiLQOXaQfC94p\no6yqmSe+ejoJsVpzLsFLI3SRz7Crpplfvl3KJdNGce4kXbdFgpsKXeQInHPc9z8biYuO4r4vFHgd\nR6RfKnSRI1iyfj/vlFTxrxdMZESa9jmX4KdCFzmMxrZO7n9tIwWj0rhu1liv44j4RW+KihzGQ29s\no7KxnUfnTScmWuMeCQ36SRU5xIY99Tzx/g7mzsjl1NyhXscR8ZsKXaSP7m7H91/dwNCkOL530WSv\n44gcFRW6SB/PryxnTXkd914yhfSkWK/jiBwVFbpIr+qmdh54fQtF44fxxVO1+ZaEHhW6SK//XLKF\nlg4fP/pnbb4loUmFLgIs317Dyx9VcMtZ45mQlep1HJFjokKXiNfh6+b7r64nZ1gi3/p8vtdxRI6Z\n1qFLxHvs3TK2VzXzuxtOJzFOm29J6NIIXSLa7poW/t9b25gzbSSfm6zNtyS0qdAlYjnnuG/xBmKi\njPsunep1HJHjpkKXiLVk/X7+trWKf71wEiPTtfmWhD4VukSkhrZOfvDHjZw4Jo3rtfmWhAm9KSoR\n6cHXt1LT1M7j1xdq8y0JG/pJloizevdBnvlgF9fNyuOk7CFexxEJGBW6RJTOrm7ueWUDWanx3H7h\nRK/jiASUplwkojz+3g4272vg19ecRmqCNt+S8KIRukSM3TUt/OLNEi4oGMHsE0d6HUck4PwqdDOb\nbWZbzazUzO76jOO+bGbOzAoDF1Hk+DnnuPfV9USbcf/lU7X5loSlfgvdzKKBR4CLgQJgrpn9wyXQ\nzSwVuA34INAhRY7X/6zZy7vbqrlz9mRGpSd6HUdkQPgzQp8BlDrnypxzHcDzwOWHOe6HwANAWwDz\niRy32uYOfvjaJk7JGcK8Iq05l/DlT6GPAcr73K7ove8TZnYakOOc+9NnfSEzm29mxWZWXFVVddRh\nRY7FD1/bRH1rJz/58jSiozTVIuHruN8UNbMo4OfA7f0d65xb4JwrdM4VZmZmHu9Ti/Trb1sreWX1\nHr5x7glMHpnmdRyRAeVPoe8Bcvrczu6972OpwInA38xsJ1AELNYbo+K1pnYf976ygQlZKXzz8xO8\njiMy4Pwp9JVAvpmNM7M44Cpg8ccPOufqnXMZzrk851wesAK4zDlXPCCJRfz0s6Vb2VvfygNfnkZ8\njPY5l/DXb6E753zArcBSYDPwgnNuo5ndb2aXDXRAkWNRvLOWJ5fv5LqisUwfO8zrOCKDwq8zRZ1z\nS4Alh9x33xGOPff4Y4kcu7bOLu58aR2j0xO5c/Zkr+OIDBqd+i9h5+dvlFBW3cyzN88kOV4/4hI5\ndOq/hJWPdh9k4btlzJ2Ry5kTMryOIzKoVOgSNj6eahmZlsA9czTVIpFHf49K2HjojRJKK5t48sYZ\n2klRIpJG6BIWinfWsqB3quWciTppTSKTCl1CXkuHj9tfXEv20ETuvWSK13FEPKMpFwl5P/nzFnbX\ntrDoliJStKpFIphG6BLSlpVU8dTyXdx45jiKxg/3Oo6Ip1ToErIONnfw3RfXkp+Vwh0XTfI6jojn\n9PephCTnHHf/YT0HWzr43VdPJyFWe7WIaIQuIenFVRW8vnE/371wElNHp3sdRyQoqNAl5Oyqaebf\nF2+kaPwwbj5rvNdxRIKGCl1CSoevm28vWk10lPFfV5yiKxCJ9KE5dAkp//WXraytqOfX15zGmCG6\n2LNIXxqhS8h4p6SK3ywr4+qZuVw8bZTXcUSCjgpdQkJlYxu3v7CGSSNSue/SAq/jiAQlTblI0Ovq\ndty2aA1N7T6eu6VISxRFjkCFLkHvoTdKWF5Ww4NfOYmJI1K9jiMStDTlIkHt7a2V/PfbpVxRmM2/\nFOZ4HUckqKnQJWjtqWvl//x+DZNHpnL/5Sd6HUck6KnQJSi1dXbx9adX4ety/HredM2bi/hBc+gS\ndJxz3PvKBtbvqeex6woZl5HsdSSRkKARugSdp5bv4uWPKvjO+flcUDDC6zgiIUOFLkHlg7Iafvja\nJs6fMoJvfz7f6zgiIUWFLkFjV00zX39mFbnDk/j5lScTpX1aRI6KCl2CQkNbJzc9WUy3g8evP520\nhFivI4mEHBW6eM7X1c2tz61mZ3Uzj86brjdBRY6RVrmIp5xz3P/aJpaVVPGTL01j1gm6LqjIsdII\nXTz16DtlPLV8F/PPHs9VM3K9jiMS0lTo4plXV+/hgde38IWTR3PX7MlexxEJeSp08cTfS6u546W1\nFI0fxs/+5SStaBEJAL8K3cxmm9lWMys1s7sO8/i/mtkmM1tnZm+Z2djAR5Vwsaa8jvlPFTM+I4Xf\nXFtIfIxO6xcJhH4L3cyigUeAi4ECYK6ZHXqFgdVAoXPuJOAl4KeBDirhYev+Rm743YcMT4nnqZtm\nkJ6o5YkigeLPCH0GUOqcK3POdQDPA5f3PcA597ZzrqX35gogO7AxJRzsqmlm3uMfEBcdxbM3z2RE\nWoLXkUTCij+FPgYo73O7ove+I7kJ+PPhHjCz+WZWbGbFVVVV/qeUkFde28LVj31AZ1c3z9w8k5xh\nSV5HEgk7AX1T1MzmAYXAg4d73Dm3wDlX6JwrzMzMDORTSxCrONjC3MdW0NjWydM3ztRVh0QGiD8n\nFu0B+l4qJrv3vk8xs/OBe4FznHPtgYknoa7iYAtXLVhBQ2snz95cxLTsdK8jiYQtf0boK4F8Mxtn\nZnHAVcDivgeY2anAb4DLnHOVgY8poWhXTfMnZf7MzTNV5iIDrN8RunPOZ2a3AkuBaOC3zrmNZnY/\nUOycW0zPFEsK8KKZAex2zl02gLklyG3d38i1j/fMmWtkLjI4/NrLxTm3BFhyyH339fn8/ADnkhC2\ntryO63/3IfExUbzwtVnka85cZFBocy4JqHdKqvjGM6sYlhLHszcVkTtcq1lEBotO/ZeAeWFlOTc+\nsZLc4cm89PUzVOYig0wjdDluzjkefmsbv3hzG2flZ/Cra04jVReoEBl0KnQ5Lq0dXdzx0lpeW7eP\nr0zP5j+/NI3YaP3hJ+IFFbocs711rcx/upiNexu46+LJfO3s8fSuchIRD6jQ5ZisKKvh1udW09bZ\nxcLrCjlvygivI4lEPBW6HJXubsdvlpXx4NIt5A1P5rlbdCq/SLBQoYvfDjZ3cMdLa3lzcyWXnDSK\nB758Einx+hESCRb6bRS/vLetmttfXENtcwc/+EIB15+Rp/lykSCjQpfP1NbZxc+WbmXhezuYkJXC\nb284namjdRq/SDBSocsRrdp1kDtfWsv2qmauLRrLPXOmkBiny8WJBCsVuvyDlg4fP/9LCY//fQej\n0xN56sYZnD1R+9eLBDsVunzKXzbu59//uIk9da1cMzOXuy6erLM+RUKECl2Anr3Lf/jaJt7cXMmk\nEam88LVZzBg3zOtYInIUVOgRrr6lk1/+dRtPLt9JbHQU986Zwg1n5un0fZEQpEKPUG2dXTyzYheP\nvF1KXWsnV0zP4fYLJ5KVluB1NBE5Rir0CNPh6+aF4nJ++ddtHGho56z8DO6+eAoFo9O8jiYix0mF\nHiFaO7p4fuVuFiwrY199G4Vjh/LwVadSNH6419FEJEBU6GGupqmdZz/YzZPv76SmuYMZecP4zy9N\n45yJmTrTUyTMqNDD1Ka9DTz5/k5eWbOHDl83507K5BvnTtDKFZEwpkIPI60dXfxx3V6e+2A3a8rr\nSIiN4orCbG44YxwTslK8jiciA0yFHuK6ux0f7qzl5VUV/HnDfprafUzISuG+Swv40mljGJIU53VE\nERkkKvQQ5JxjbUU9f1q3lyXr97OnrpXkuGjmTBvFV6ZnM2PcMM2Pi0QgFXqI6Ozq5sMdtbyx6QBv\nbDrAnrpWYqONs/MzueOiSVw0daQ2zhKJcCr0ILa3rpVlJVW8U1LFe6XVNLb5iI+J4qz8DG47P5+L\nCkaSnqR9VkSkhwo9iOyvb2PlzlqWl9WwfHsNO6qbARiVnsCcE0fx+SlZnJWfQVKcvm0i8o/UDB7p\n8HWzZX8Da8rrWL27juJdtZTXtgKQGh/DjHHDuGZmLmdPzCQ/K0Vz4iLSLxX6IGhq97F1fyNb9jew\nYU8DG/fWs2VfIx1d3QBkpMRTOHYo18/K4/S8YUwdnUaMNscSkaOkQg8Q5xy1zR3sqG6mrKqZ0qom\nSiub2FbZ+MnIGyA9MZapo9O44cw8Ts4ewsk56YwZkqgRuIgcNxX6UWhu97G3rpWKulb2HGyl4mAr\n5bUt7K5tYVdNMw1tvk+OjYuOYnxmMidnD+HKwhwmj0xj0shUsoeqvEVkYER8oXd3O+pbO6lp7qCm\nqZ3qpg6qGtuoamrnQEM7BxraONDQxr76Nhr7FDZAbLSRMzSJnGFJnJIzhLyMZMZnJJOXkUzO0ERN\nm4jIoPKr0M1sNvAwEA0sdM795JDH44GngOlADXClc25nYKMennOOdl83Te0+mtt9NLb5aGr30dTm\no6Gtk8Y2Hw2tndS3dlL38ceWDg62/O/Hrm73D183OsrISo0nKzWescOTmTV+OCPTExk9JIExQxIZ\nMzSRrNQEoqM02haR4NBvoZtZNPAIcAFQAaw0s8XOuU19DrsJOOicm2BmVwEPAFcOROAXVpbz6LLt\ntLR30dzho6Wj67CFfKikuGjSE2NJT4xlSFIs+VkpDEmKY3hyHMOS4xieEsfw5HgyUuPISIlnWFIc\nUSprEQkh/ozQZwClzrkyADN7Hrgc6FvolwM/6P38JeC/zcycc/037VEamhxHwag0kuKiSYqLISku\nmuT4GFLiY0iOjyE1IYbU+BhSEmJIS4glLTGWlPgY4mI0/SEi4c2fQh8DlPe5XQHMPNIxzjmfmdUD\nw4HqvgeZ2XxgPkBubu4xBb6gYAQXFIw4pn8rIhLOBnXY6pxb4JwrdM4VZmZmDuZTi4iEPX8KfQ+Q\n0+d2du99hz3GzGKAdHreHBURkUHiT6GvBPLNbJyZxQFXAYsPOWYxcH3v518B/joQ8+ciInJk/c6h\n986J3wospWfZ4m+dcxvN7H6g2Dm3GHgceNrMSoFaekpfREQGkV/r0J1zS4Alh9x3X5/P24B/CWw0\nERE5GlrLJyISJlToIiJhQoUuIhImzKvFKGZWBezy5MmPTwaHnDAVISLxdes1R45Qet1jnXOHPZHH\ns0IPVWZW7Jwr9DrHYIvE163XHDnC5XVrykVEJEyo0EVEwoQK/egt8DqARyLxdes1R46weN2aQxcR\nCRMaoYuIhAkVuohImFChHwczu93MnJlleJ1loJnZg2a2xczWmdkrZjbE60wDycxmm9lWMys1s7u8\nzjPQzCzHzN42s01mttHMbvM602Axs2gzW21mr3md5Xip0I+RmeUAFwK7vc4ySN4ATnTOnQSUAHd7\nnGfA9LmO7sVAATDXzAq8TTXgfMDtzrkCoAj4ZgS85o/dBmz2OkQgqNCP3UPAnUBEvKvsnPuLc87X\ne3MFPRc6CVefXEfXOdcBfHwd3bDlnNvnnPuo9/NGegpujLepBp6ZZQOXAAu9zhIIKvRjYGaXA3uc\nc2u9zuKRG4E/ex1iAB3uOrphX24fM7M84FTgA2+TDIpf0DMw6/Y6SCD4tR96JDKzN4GRh3noXuAe\neqZbwspnvWbn3P/0HnMvPX+ePzuY2WRwmFkK8DLwHedcg9d5BpKZXQpUOudWmdm5XucJBBX6ETjn\nzj/c/WY2DRgHrDUz6Jl6+MjMZjjn9g9ixIA70mv+mJndAFwKnBfmlxj05zq6YcfMYukp82edc3/w\nOs8gOBO4zMzmAAlAmpk945yb53GuY6YTi46Tme0ECp1zobJT2zExs9nAz4FznHNVXucZSL0XOi8B\nzqOnyFcCVzvnNnoabABZz+jkSaDWOfcdr/MMtt4R+nedc5d6neV4aA5d/PXfQCrwhpmtMbNHvQ40\nUHrf/P34OrqbgRfCucx7nQlcC3y+9/u7pnfkKiFEI3QRkTChEbqISJhQoYuIhAkVuohImFChi4iE\nCRW6iEiYUKGLiIQJFbqISJj4/0tmGO21nq61AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcwDYc4sQXBh",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xH8cK19FNWxo",
        "colab_type": "code",
        "outputId": "87b1ff50-115d-4275-90d1-24375b9c6c27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "#relu\n",
        "y_relu = torch.relu(x)\n",
        "\n",
        "plt.plot(x.numpy(), y_relu.numpy())\n",
        "plt.show()"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nO+DDN3zzAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jd1gGsVdNu-N",
        "colab_type": "code",
        "outputId": "7e023aa0-f896-427a-ae39-7c97a138d32c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "#leaky relu\n",
        "\"\"\"To mitigate that effect, variants such as the Leaky ReLU and Parametric ReLU\n",
        "(PReLU) activation functions have proposed, where the leak coefficient a is a\n",
        "learned parameter\n",
        "\"\"\"\n",
        "prelu = torch.nn.PReLU(num_parameters=1)\n",
        "\n",
        "y_prelu = prelu(x)\n",
        "\n",
        "plt.plot(x.numpy(), y_prelu.detach().numpy())\n",
        "plt.show()"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD4CAYAAADxeG0DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7P7GrYTOg0S",
        "colab_type": "code",
        "outputId": "083ce630-41bf-4011-e3a6-84825dd18133",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#Softmax\n",
        "\"\"\"Another choice for the activation function is the softmax. Like the sigmoid\n",
        "function, the softmax function squashes the output of each unit to be between 0\n",
        "and 1, as shown in Example 3-6. However, the softmax operation also divides\n",
        "each output by the sum of all the outputs, which gives us a discrete probability\n",
        "distribution over k possible classes:\n",
        "\"\"\"\n",
        "softmax = nn.Softmax(dim =1)\n",
        "\n",
        "x_input = torch.randn(1, 3)\n",
        "\n",
        "y_output = softmax(x_input)\n",
        "\n",
        "print(x_input)\n",
        "\n",
        "print(y_output)"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0860, -1.3576, -0.0027]])\n",
            "tensor([[0.4649, 0.1097, 0.4254]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnaVUjprQdKl",
        "colab_type": "text"
      },
      "source": [
        "# Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ladh3PUJQfAW",
        "colab_type": "code",
        "outputId": "7f6f039e-44e3-4fb1-9514-b559e8cf8ff2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#RMSE/MSE for regular regression\n",
        "mse_loss = nn.MSELoss()\n",
        "\n",
        "#predict\n",
        "output = torch.randn(3, 5, requires_grad=True)\n",
        "\n",
        "#real label\n",
        "targets = torch.randn(3, 5)\n",
        "\n",
        "#calculate loss\n",
        "loss = mse_loss(output, targets)\n",
        "print(loss)"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1.1700, grad_fn=<MseLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z94Iq_diSCYP",
        "colab_type": "code",
        "outputId": "c607100a-db74-4c1f-c9c8-e95856408682",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#category cross-entropy loss\n",
        "\"\"\"The categorical cross-entropy loss is typically used in a multiclass classification\n",
        "setting in which the outputs are interpreted as predictions of class membership\n",
        "probabilities. The target (y) is a vector of n elements that represents the true\n",
        "multinomial distribution over all the classes. If only one class is correct, this\n",
        "vector is a one-hot vector. The network’s output (ŷ) is also a vector of n elements\n",
        "but represents the network’s prediction of the multinomial distribution.\n",
        "Categorical cross entropy will compare these two vectors (y,ŷ) to measure the\n",
        "loss:\n",
        "  We want the probability of the\n",
        "correct class to be close to 1, whereas the other\"\"\"\n",
        "\n",
        "ce_loss = nn.CrossEntropyLoss()\n",
        "\n",
        "#\n",
        "outputs = torch.randn(3, 5, requires_grad=True)\n",
        "\n",
        "#class labels\n",
        "targets = torch.tensor([1, 0, 3], dtype = torch.int64)\n",
        "\n",
        "loss = ce_loss(outputs, targets)\n",
        "\n",
        "print(loss)"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.1900, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lY40weuiUW7M",
        "colab_type": "code",
        "outputId": "b3320c94-c4dd-4b63-e52f-2dc80a341e0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "#Binary Cross-Entropy Loss\n",
        "bce = nn.BCELoss()\n",
        "\n",
        "sigmoid = nn.Sigmoid()\n",
        "\n",
        "#create probabilities\n",
        "prob = sigmoid(torch.randn(4, 1, requires_grad=True))\n",
        "\n",
        "targets = torch.tensor([1, 0, 1, 0], dtype=torch.float32).view(4, 1)\n",
        "\n",
        "loss = bce(prob, targets)\n",
        "\n",
        "print(prob)\n",
        "\n",
        "print(loss)"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.7893],\n",
            "        [0.3976],\n",
            "        [0.3114],\n",
            "        [0.5031]], grad_fn=<SigmoidBackward>)\n",
            "tensor(0.6523, grad_fn=<BinaryCrossEntropyBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDaiQwj2WKtc",
        "colab_type": "text"
      },
      "source": [
        "# Supervised Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feYIyhpYYiJL",
        "colab_type": "text"
      },
      "source": [
        "Supervised learning requires the following: a model, a\n",
        "loss function, training data, and an optimization algorithm. \n",
        "<br>\n",
        "* The training data for supervised learning is pairs of observations and targets; \n",
        "* the model computes\n",
        "predictions from the observations, and the loss measures the error of the\n",
        "predictions as compared to the targets. \n",
        "* The goal of the training is to use the gradient-based optimization algorithm to adjust the model’s parameters so that\n",
        "the losses are as low as possible"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZriRRC-WNlu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#instantiating the Adam optimizer9default learning rate is 0.001\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "input_dim = 2 #2 d array\n",
        "lr = 0.001\n",
        "\n",
        "#this is the model we initiate before\n",
        "perceptron = Perceptron(input_dim=input_dim)\n",
        "\n",
        "bce_loss = nn.BCELoss()\n",
        "\n",
        "#https://pytorch.org/docs/stable/optim.html\n",
        "optimizer = optim.Adam(params=perceptron.parameters(), lr = lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Po3gM3JGVtOM",
        "colab_type": "code",
        "outputId": "66e5030b-c3d5-484f-e4c2-6365c655cbbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#starting from calculating loss, and then optimize parameters\n",
        "\"\"\"\n",
        "#each epoch is a complete pass over the training data\n",
        "for epoch_i in range(n_epochs):\n",
        "  #the inner loop is over the batches in the dataset\n",
        "  for batch_in in range(n_batches):\n",
        "\n",
        "    #step 0: Get the data(batch_size)\n",
        "    x_data, y_target = get_toy_data(batch_size)\n",
        "\n",
        "    #step 1: Clear the gradients\n",
        "    perceptron.zero_grad()\n",
        "\n",
        "    #step 2: Compute the forward pass of the model\n",
        "    y_pred = perceptron(x_data, apply_sigmoid = True)\n",
        "\n",
        "    #step 3: Compute the loss value that we wish to optimize\n",
        "    loss = bce_loss(y_pred, y_target)\n",
        "\n",
        "    #step 4: Propagate the loss signal backward\n",
        "    loss.backward()\n",
        "\n",
        "    #step 5: Trigger the optimizer to perform one update\n",
        "    optimizer.step()\n",
        "\n",
        "# the core idea of supervised gradient-based learning is: define a model, computes the output, use a loss function to compute the gradients, and apply an optimizer to update model parameters with the gradient.\n",
        "\"\"\""
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n#each epoch is a complete pass over the training data\\nfor epoch_i in range(n_epochs):\\n  #the inner loop is over the batches in the dataset\\n  for batch_in in range(n_batches):\\n\\n    #step 0: Get the data(batch_size)\\n    x_data, y_target = get_toy_data(batch_size)\\n\\n    #step 1: Clear the gradients\\n    perceptron.zero_grad()\\n\\n    #step 2: Compute the forward pass of the model\\n    y_pred = perceptron(x_data, apply_sigmoid = True)\\n\\n    #step 3: Compute the loss value that we wish to optimize\\n    loss = bce_loss(y_pred, y_target)\\n\\n    #step 4: Propagate the loss signal backward\\n    loss.backward()\\n\\n    #step 5: Trigger the optimizer to perform one update\\n    optimizer.step()\\n\\n# the core idea of supervised gradient-based learning is: define a model, computes the output, use a loss function to compute the gradients, and apply an optimizer to update model parameters with the gradient.\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysmXtzfFjwvp",
        "colab_type": "text"
      },
      "source": [
        "# Case Study: Classifiying Sentiment of Restarurant Review\n",
        "To summarize, you should use the training partition of a dataset to derive model\n",
        "parameters, the validation partition of a dataset for selecting among\n",
        "hyperparameters (making modeling decisions), and the testing partition of the\n",
        "dataset for final evaluation and reporting.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUjUp7QBfqPg",
        "colab_type": "code",
        "outputId": "de82c00e-4a6e-4af4-cbd2-461db397d37f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "root_dir = \"/content/gdrive/My Drive/\"\n",
        "base_dir = root_dir + 'Colab Notebooks/'"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVKIp4nKxGS1",
        "colab_type": "code",
        "outputId": "fa7b0124-f52f-448c-ab6a-babb51da7619",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "#set up the path to read data\n",
        "path = Path(base_dir + 'data/yelp_review/')\n",
        "os.chdir(path)\n",
        "os.listdir()"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['reviews_with_splits_lite.csv',\n",
              " 'raw_test.csv',\n",
              " 'raw_train.csv',\n",
              " 'model_storage',\n",
              " 'yelp_review']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXlmGRRSxsIv",
        "colab_type": "code",
        "outputId": "42fcde2a-ed06-4c8e-8fd8-6c5ed7a14cff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "args = Namespace(\n",
        "    raw_train = 'raw_train.csv',\n",
        "    raw_test = 'raw_test.csv',\n",
        "    proportion_subset_of_train = 0.1,\n",
        "    train_proportion = 0.7,\n",
        "    val_proportion = 0.15,\n",
        "    test_proportion = 0.15,\n",
        "    output_munged_csv = 'reviews_with_splits_lite.csv',\n",
        "    seed = 1337\n",
        ")\n",
        "\n",
        "#read the raw data\n",
        "train_reviews = pd.read_csv(args.raw_train, header = None, names = ['rating', 'review'])\n",
        "train_reviews.rating.value_counts()"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    280000\n",
              "1    280000\n",
              "Name: rating, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONHh-MDLNMyu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#make the subset equal across the review classes\n",
        "by_rating = collections.defaultdict(list)\n",
        "\n",
        "for _, row in train_reviews.iterrows():\n",
        "  by_rating[row.rating].append(row.to_dict())\n",
        "\n",
        "review_subset = []\n",
        "\n",
        "for _, item_list in sorted(by_rating.items()):\n",
        "\n",
        "  n_total = len(item_list)\n",
        "  n_subset = int(args.proportion_subset_of_train * n_total)\n",
        "  review_subset.extend(item_list[:n_subset])\n",
        "\n",
        "review_subset = pd.DataFrame(review_subset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2B7_dXXQni8",
        "colab_type": "code",
        "outputId": "a085f506-9c46-49e0-b81a-0684da4cf142",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "review_subset.sample(5)"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rating</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7964</th>\n",
              "      <td>1</td>\n",
              "      <td>Ok so we always drive by Jordan's and wonder i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48251</th>\n",
              "      <td>2</td>\n",
              "      <td>Love this groomer. Very good at getting my pet...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55893</th>\n",
              "      <td>2</td>\n",
              "      <td>Wine selection is FANTASTIC!\\nThis place is a ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10038</th>\n",
              "      <td>1</td>\n",
              "      <td>Really LGO?! I quit going to my neighborhood s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53310</th>\n",
              "      <td>2</td>\n",
              "      <td>i have been to this place quite few times alre...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       rating                                             review\n",
              "7964        1  Ok so we always drive by Jordan's and wonder i...\n",
              "48251       2  Love this groomer. Very good at getting my pet...\n",
              "55893       2  Wine selection is FANTASTIC!\\nThis place is a ...\n",
              "10038       1  Really LGO?! I quit going to my neighborhood s...\n",
              "53310       2  i have been to this place quite few times alre..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6l6JKgKR0GU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Splitting the subset by rating to create our new train, val, and test splits\n",
        "by_rating = collections.defaultdict(list)\n",
        "for _, row in review_subset.iterrows():\n",
        "    by_rating[row.rating].append(row.to_dict())\n",
        "    \n",
        "final_list = []\n",
        "np.random.seed(args.seed)\n",
        "\n",
        "for _, item_list in sorted(by_rating.items()):\n",
        "\n",
        "    np.random.shuffle(item_list)\n",
        "    \n",
        "    n_total = len(item_list)\n",
        "    n_train = int(args.train_proportion * n_total)\n",
        "    n_val = int(args.val_proportion * n_total)\n",
        "    n_test = int(args.test_proportion * n_total)\n",
        "    \n",
        "    # Give data point a split attribute\n",
        "    for item in item_list[:n_train]:\n",
        "        item['split'] = 'train'\n",
        "    \n",
        "    for item in item_list[n_train:n_train+n_val]:\n",
        "        item['split'] = 'val'\n",
        "        \n",
        "    for item in item_list[n_train+n_val:n_train+n_val+n_test]:\n",
        "        item['split'] = 'test'\n",
        "\n",
        "    # Add to final list\n",
        "    final_list.extend(item_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSRHRMF2S31U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_list = []\n",
        "np.random.seed(args.seed)\n",
        "\n",
        "for _, item_list in sorted(by_rating.items()):\n",
        "\n",
        "    np.random.shuffle(item_list)\n",
        "    \n",
        "    n_total = len(item_list)\n",
        "    n_train = int(args.train_proportion * n_total)\n",
        "    n_val = int(args.val_proportion * n_total)\n",
        "    n_test = int(args.test_proportion * n_total)\n",
        "    \n",
        "    # Give data point a split attribute\n",
        "    for item in item_list[:n_train]:\n",
        "        item['split'] = 'train'\n",
        "    \n",
        "    for item in item_list[n_train:n_train+n_val]:\n",
        "        item['split'] = 'val'\n",
        "        \n",
        "    for item in item_list[n_train+n_val:n_train+n_val+n_test]:\n",
        "        item['split'] = 'test'\n",
        "\n",
        "    # Add to final list\n",
        "    final_list.extend(item_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvEIjeUhS5v1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Write split data to file\n",
        "final_reviews = pd.DataFrame(final_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYvUMbdYS9Y7",
        "colab_type": "code",
        "outputId": "6729a4c2-ce55-4c73-c880-323607756048",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "final_reviews.split.value_counts()"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "train    39200\n",
              "val       8400\n",
              "test      8400\n",
              "Name: split, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Arqu9qGXTD17",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preprocess the reviews\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"([.,!?])\", r\" \\1 \", text)\n",
        "    text = re.sub(r\"[^a-zA-Z.,!?]+\", r\" \", text)\n",
        "    return text\n",
        "    \n",
        "final_reviews.review = final_reviews.review.apply(preprocess_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMMtu1P2TIJA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create a new column indicator\n",
        "final_reviews['rating'] = final_reviews.rating.apply({1: 'negative', 2: 'positive'}.get)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYKu0_knTLgI",
        "colab_type": "code",
        "outputId": "6f94dfb8-f383-4589-f160-d1fe1a519d77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "final_reviews.head()"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rating</th>\n",
              "      <th>review</th>\n",
              "      <th>split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>negative</td>\n",
              "      <td>all i can say is that a i had no other option ...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>negative</td>\n",
              "      <td>i went here once when my long time stylist mov...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>negative</td>\n",
              "      <td>i don t know why i stopped here for lunch this...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negative</td>\n",
              "      <td>did i order the wrong thing ? or maybe it was ...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>negative</td>\n",
              "      <td>i went here for restaurant week . the restaura...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     rating                                             review  split\n",
              "0  negative  all i can say is that a i had no other option ...  train\n",
              "1  negative  i went here once when my long time stylist mov...  train\n",
              "2  negative  i don t know why i stopped here for lunch this...  train\n",
              "3  negative  did i order the wrong thing ? or maybe it was ...  train\n",
              "4  negative  i went here for restaurant week . the restaura...  train"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqIfHUPHlmEk",
        "colab_type": "text"
      },
      "source": [
        "## The Vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxzpNZ9sXtAm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Vocabulary(object):\n",
        "    \"\"\"Class to process text and extract vocabulary for mapping\"\"\"\n",
        "\n",
        "    def __init__(self, token_to_idx=None, add_unk=True, unk_token=\"<UNK>\"):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            token_to_idx (dict): a pre-existing map of tokens to indices\n",
        "            add_unk (bool): a flag that indicates whether to add the UNK token\n",
        "            unk_token (str): the UNK token to add into the Vocabulary\n",
        "        \"\"\"\n",
        "\n",
        "        if token_to_idx is None:\n",
        "            token_to_idx = {}\n",
        "        self._token_to_idx = token_to_idx\n",
        "\n",
        "        self._idx_to_token = {idx: token \n",
        "                              for token, idx in self._token_to_idx.items()}\n",
        "        \n",
        "        self._add_unk = add_unk\n",
        "        self._unk_token = unk_token\n",
        "        \n",
        "        self.unk_index = -1\n",
        "        if add_unk:\n",
        "            self.unk_index = self.add_token(unk_token) \n",
        "        \n",
        "        \n",
        "    def to_serializable(self):\n",
        "        \"\"\" returns a dictionary that can be serialized \"\"\"\n",
        "        return {'token_to_idx': self._token_to_idx, \n",
        "                'add_unk': self._add_unk, \n",
        "                'unk_token': self._unk_token}\n",
        "\n",
        "    @classmethod\n",
        "    def from_serializable(cls, contents):\n",
        "        \"\"\" instantiates the Vocabulary from a serialized dictionary \"\"\"\n",
        "        return cls(**contents)\n",
        "\n",
        "    def add_token(self, token):\n",
        "        \"\"\"Update mapping dicts based on the token.\n",
        "\n",
        "        Args:\n",
        "            token (str): the item to add into the Vocabulary\n",
        "        Returns:\n",
        "            index (int): the integer corresponding to the token\n",
        "        \"\"\"\n",
        "        if token in self._token_to_idx:\n",
        "            index = self._token_to_idx[token]\n",
        "        else:\n",
        "            index = len(self._token_to_idx)\n",
        "            self._token_to_idx[token] = index\n",
        "            self._idx_to_token[index] = token\n",
        "        return index\n",
        "    \n",
        "    def add_many(self, tokens):\n",
        "        \"\"\"Add a list of tokens into the Vocabulary\n",
        "        \n",
        "        Args:\n",
        "            tokens (list): a list of string tokens\n",
        "        Returns:\n",
        "            indices (list): a list of indices corresponding to the tokens\n",
        "        \"\"\"\n",
        "        return [self.add_token(token) for token in tokens]\n",
        "\n",
        "    def lookup_token(self, token):\n",
        "        \"\"\"Retrieve the index associated with the token \n",
        "          or the UNK index if token isn't present.\n",
        "        \n",
        "        Args:\n",
        "            token (str): the token to look up \n",
        "        Returns:\n",
        "            index (int): the index corresponding to the token\n",
        "        Notes:\n",
        "            `unk_index` needs to be >=0 (having been added into the Vocabulary) \n",
        "              for the UNK functionality \n",
        "        \"\"\"\n",
        "        if self.unk_index >= 0:\n",
        "            return self._token_to_idx.get(token, self.unk_index)\n",
        "        else:\n",
        "            return self._token_to_idx[token]\n",
        "\n",
        "    def lookup_index(self, index):\n",
        "        \"\"\"Return the token associated with the index\n",
        "        \n",
        "        Args: \n",
        "            index (int): the index to look up\n",
        "        Returns:\n",
        "            token (str): the token corresponding to the index\n",
        "        Raises:\n",
        "            KeyError: if the index is not in the Vocabulary\n",
        "        \"\"\"\n",
        "        if index not in self._idx_to_token:\n",
        "            raise KeyError(\"the index (%d) is not in the Vocabulary\" % index)\n",
        "        return self._idx_to_token[index]\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"<Vocabulary(size=%d)>\" % len(self)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._token_to_idx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6r4Ku6H7lo4T",
        "colab_type": "text"
      },
      "source": [
        "## Vectorization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ROO1C-vX0Nq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ReviewVectorizer(object):\n",
        "    \"\"\" The Vectorizer which coordinates the Vocabularies and puts them to use\"\"\"\n",
        "    def __init__(self, review_vocab, rating_vocab):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            review_vocab (Vocabulary): maps words to integers\n",
        "            rating_vocab (Vocabulary): maps class labels to integers\n",
        "        \"\"\"\n",
        "        self.review_vocab = review_vocab\n",
        "        self.rating_vocab = rating_vocab\n",
        "\n",
        "    def vectorize(self, review):\n",
        "        \"\"\"Create a collapsed one-hit vector for the review\n",
        "        \n",
        "        Args:\n",
        "            review (str): the review \n",
        "        Returns:\n",
        "            one_hot (np.ndarray): the collapsed one-hot encoding \n",
        "        \"\"\"\n",
        "        one_hot = np.zeros(len(self.review_vocab), dtype=np.float32)\n",
        "        \n",
        "        for token in review.split(\" \"):\n",
        "            if token not in string.punctuation:\n",
        "                one_hot[self.review_vocab.lookup_token(token)] = 1\n",
        "\n",
        "        return one_hot\n",
        "\n",
        "    @classmethod\n",
        "    def from_dataframe(cls, review_df, cutoff=25):\n",
        "        \"\"\"Instantiate the vectorizer from the dataset dataframe\n",
        "        \n",
        "        Args:\n",
        "            review_df (pandas.DataFrame): the review dataset\n",
        "            cutoff (int): the parameter for frequency-based filtering\n",
        "        Returns:\n",
        "            an instance of the ReviewVectorizer\n",
        "        \"\"\"\n",
        "        review_vocab = Vocabulary(add_unk=True)\n",
        "        rating_vocab = Vocabulary(add_unk=False)\n",
        "        \n",
        "        # Add ratings\n",
        "        for rating in sorted(set(review_df.rating)):\n",
        "            rating_vocab.add_token(rating)\n",
        "\n",
        "        # Add top words if count > provided count\n",
        "        word_counts = Counter()\n",
        "        for review in review_df.review:\n",
        "            for word in review.split(\" \"):\n",
        "                if word not in string.punctuation:\n",
        "                    word_counts[word] += 1\n",
        "               \n",
        "        for word, count in word_counts.items():\n",
        "            if count > cutoff:\n",
        "                review_vocab.add_token(word)\n",
        "\n",
        "        return cls(review_vocab, rating_vocab)\n",
        "\n",
        "    @classmethod\n",
        "    def from_serializable(cls, contents):\n",
        "        \"\"\"Instantiate a ReviewVectorizer from a serializable dictionary\n",
        "        \n",
        "        Args:\n",
        "            contents (dict): the serializable dictionary\n",
        "        Returns:\n",
        "            an instance of the ReviewVectorizer class\n",
        "        \"\"\"\n",
        "        review_vocab = Vocabulary.from_serializable(contents['review_vocab'])\n",
        "        rating_vocab =  Vocabulary.from_serializable(contents['rating_vocab'])\n",
        "\n",
        "        return cls(review_vocab=review_vocab, rating_vocab=rating_vocab)\n",
        "\n",
        "    def to_serializable(self):\n",
        "        \"\"\"Create the serializable dictionary for caching\n",
        "        \n",
        "        Returns:\n",
        "            contents (dict): the serializable dictionary\n",
        "        \"\"\"\n",
        "        return {'review_vocab': self.review_vocab.to_serializable(),\n",
        "                'rating_vocab': self.rating_vocab.to_serializable()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0o9RPih8lsjR",
        "colab_type": "text"
      },
      "source": [
        "## Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcAM43qcVJCu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Dataset class is an abstract iterator, so must first sublcass(or inherit from) the Dataset class and implement __getitem__() and __len()__ method\n",
        "class ReviewDataset(Dataset):\n",
        "    def __init__(self, review_df, vectorizer):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            review_df (pandas.DataFrame): the dataset\n",
        "            vectorizer (ReviewVectorizer): vectorizer instantiated from dataset\n",
        "        \"\"\"\n",
        "        self.review_df = review_df\n",
        "        self._vectorizer = vectorizer\n",
        "\n",
        "        #return train, val and test dataset\n",
        "        self.train_df = self.review_df[self.review_df.split=='train']\n",
        "        self.train_size = len(self.train_df)\n",
        "\n",
        "        self.val_df = self.review_df[self.review_df.split=='val']\n",
        "        self.validation_size = len(self.val_df)\n",
        "\n",
        "        self.test_df = self.review_df[self.review_df.split=='test']\n",
        "        self.test_size = len(self.test_df)\n",
        "\n",
        "        self._lookup_dict = {'train': (self.train_df, self.train_size),\n",
        "                             'val': (self.val_df, self.validation_size),\n",
        "                             'test': (self.test_df, self.test_size)}\n",
        "\n",
        "        self.set_split('train')\n",
        "\n",
        "    @classmethod\n",
        "    def load_dataset_and_make_vectorizer(cls, review_csv):\n",
        "        \"\"\"Load dataset and make a new vectorizer from scratch\n",
        "        \n",
        "        Args:\n",
        "            review_csv (str): location of the dataset\n",
        "        Returns:\n",
        "            an instance of ReviewDataset\n",
        "        \"\"\"\n",
        "        review_df = pd.read_csv(review_csv)\n",
        "        train_review_df = review_df[review_df.split=='train']\n",
        "        return cls(review_df, ReviewVectorizer.from_dataframe(train_review_df))\n",
        "    \n",
        "    @classmethod\n",
        "    def load_dataset_and_load_vectorizer(cls, review_csv, vectorizer_filepath):\n",
        "        \"\"\"Load dataset and the corresponding vectorizer. \n",
        "        Used in the case in the vectorizer has been cached for re-use\n",
        "        \n",
        "        Args:\n",
        "            review_csv (str): location of the dataset\n",
        "            vectorizer_filepath (str): location of the saved vectorizer\n",
        "        Returns:\n",
        "            an instance of ReviewDataset\n",
        "        \"\"\"\n",
        "        review_df = pd.read_csv(review_csv)\n",
        "        vectorizer = cls.load_vectorizer_only(vectorizer_filepath)\n",
        "        return cls(review_df, vectorizer)\n",
        "\n",
        "    @staticmethod\n",
        "    def load_vectorizer_only(vectorizer_filepath):\n",
        "        \"\"\"a static method for loading the vectorizer from file\n",
        "        \n",
        "        Args:\n",
        "            vectorizer_filepath (str): the location of the serialized vectorizer\n",
        "        Returns:\n",
        "            an instance of ReviewVectorizer\n",
        "        \"\"\"\n",
        "        with open(vectorizer_filepath) as fp:\n",
        "            return ReviewVectorizer.from_serializable(json.load(fp))\n",
        "\n",
        "    def save_vectorizer(self, vectorizer_filepath):\n",
        "        \"\"\"saves the vectorizer to disk using json\n",
        "        \n",
        "        Args:\n",
        "            vectorizer_filepath (str): the location to save the vectorizer\n",
        "        \"\"\"\n",
        "        with open(vectorizer_filepath, \"w\") as fp:\n",
        "            json.dump(self._vectorizer.to_serializable(), fp)\n",
        "\n",
        "    def get_vectorizer(self):\n",
        "        \"\"\" returns the vectorizer \"\"\"\n",
        "        return self._vectorizer\n",
        "\n",
        "    def set_split(self, split=\"train\"):\n",
        "        \"\"\" selects the splits in the dataset using a column in the dataframe \n",
        "        \n",
        "        Args:\n",
        "            split (str): one of \"train\", \"val\", or \"test\"\n",
        "        \"\"\"\n",
        "        self._target_split = split\n",
        "        self._target_df, self._target_size = self._lookup_dict[split]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self._target_size\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"the primary entry point method for PyTorch datasets\n",
        "        \n",
        "        Args:\n",
        "            index (int): the index to the data point \n",
        "        Returns:\n",
        "            a dictionary holding the data point's features (x_data) and label (y_target)\n",
        "        \"\"\"\n",
        "        row = self._target_df.iloc[index]\n",
        "\n",
        "        review_vector = \\\n",
        "            self._vectorizer.vectorize(row.review)\n",
        "\n",
        "        rating_index = \\\n",
        "            self._vectorizer.rating_vocab.lookup_token(row.rating)\n",
        "\n",
        "        return {'x_data': review_vector,\n",
        "                'y_target': rating_index}\n",
        "\n",
        "    def get_num_batches(self, batch_size):\n",
        "        \"\"\"Given a batch size, return the number of batches in the dataset\n",
        "        \n",
        "        Args:\n",
        "            batch_size (int)\n",
        "        Returns:\n",
        "            number of batches in the dataset\n",
        "        \"\"\"\n",
        "        return len(self) // batch_size  \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPrTPOkFhP7d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#return a Pytorch iterator that groups and collates the data points provided in the Dataset\n",
        "def generate_batches(dataset, batch_size, shuffle=True,\n",
        "                     drop_last=True, device=\"cpu\"):\n",
        "    \"\"\"\n",
        "    A generator function which wraps the PyTorch DataLoader. It will \n",
        "      ensure each tensor is on the write device location.\n",
        "    \"\"\"\n",
        "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
        "                            shuffle=shuffle, drop_last=drop_last)\n",
        "\n",
        "    for data_dict in dataloader:\n",
        "        out_data_dict = {}\n",
        "        for name, tensor in data_dict.items():\n",
        "            out_data_dict[name] = data_dict[name].to(device)\n",
        "        yield out_data_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3c-Tcuablx7M",
        "colab_type": "text"
      },
      "source": [
        "## The Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYSaYarzX3vZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ReviewClassifier(nn.Module):\n",
        "    \"\"\" a simple perceptron based classifier \"\"\"\n",
        "    def __init__(self, num_features):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            num_features (int): the size of the input feature vector\n",
        "        \"\"\"\n",
        "        super(ReviewClassifier, self).__init__()\n",
        "        #create a single Linear Layer with a single output\n",
        "        #because the problem is a binary classification problem\n",
        "        self.fc1 = nn.Linear(in_features=num_features, \n",
        "                             out_features=1)\n",
        "\n",
        "    def forward(self, x_in, apply_sigmoid=False):\n",
        "        \"\"\"The forward pass of the classifier\n",
        "        \n",
        "        Args:\n",
        "            x_in (torch.Tensor): an input data tensor. \n",
        "                x_in.shape should be (batch, num_features)\n",
        "            apply_sigmoid (bool): a flag for the sigmoid activation\n",
        "                should be false if used with the Cross Entropy losses\n",
        "        Returns:\n",
        "            the resulting tensor. tensor.shape should be (batch,)\n",
        "        \"\"\"\n",
        "        y_out = self.fc1(x_in).squeeze()\n",
        "        if apply_sigmoid:\n",
        "            y_out = torch.sigmoid(y_out)\n",
        "        return y_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4nExrF5kAMQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Hyperparameters and program options for the classifer\n",
        "#Define a small dictionary that we used to trak more details about training rountine\n",
        "def make_train_state(args):\n",
        "    return {'stop_early': False,\n",
        "            'early_stopping_step': 0,\n",
        "            'early_stopping_best_val': 1e8,\n",
        "            'learning_rate': args.learning_rate,\n",
        "            'epoch_index': 0,\n",
        "            'train_loss': [],\n",
        "            'train_acc': [],\n",
        "            'val_loss': [],\n",
        "            'val_acc': [],\n",
        "            'test_loss': -1,\n",
        "            'test_acc': -1,\n",
        "            'model_filename': args.model_state_file}\n",
        "\n",
        "def update_train_state(args, model, train_state):\n",
        "    \"\"\"Handle the training state updates.\n",
        "\n",
        "    Components:\n",
        "     - Early Stopping: Prevent overfitting.\n",
        "     - Model Checkpoint: Model is saved if the model is better\n",
        "\n",
        "    :param args: main arguments\n",
        "    :param model: model to train\n",
        "    :param train_state: a dictionary representing the training state values\n",
        "    :returns:\n",
        "        a new train_state\n",
        "    \"\"\"\n",
        "\n",
        "    # Save one model at least\n",
        "    if train_state['epoch_index'] == 0:\n",
        "        torch.save(model.state_dict(), train_state['model_filename'])\n",
        "        train_state['stop_early'] = False\n",
        "\n",
        "    # Save model if performance improved\n",
        "    elif train_state['epoch_index'] >= 1:\n",
        "        loss_tm1, loss_t = train_state['val_loss'][-2:]\n",
        "\n",
        "        # If loss worsened\n",
        "        if loss_t >= train_state['early_stopping_best_val']:\n",
        "            # Update step\n",
        "            train_state['early_stopping_step'] += 1\n",
        "        # Loss decreased\n",
        "        else:\n",
        "            # Save the best model\n",
        "            if loss_t < train_state['early_stopping_best_val']:\n",
        "                torch.save(model.state_dict(), train_state['model_filename'])\n",
        "\n",
        "            # Reset early stopping step\n",
        "            train_state['early_stopping_step'] = 0\n",
        "\n",
        "        # Stop early ?\n",
        "        train_state['stop_early'] = \\\n",
        "            train_state['early_stopping_step'] >= args.early_stopping_criteria\n",
        "\n",
        "    return train_state\n",
        "\n",
        "def compute_accuracy(y_pred, y_target):\n",
        "    y_target = y_target.cpu()\n",
        "    y_pred_indices = (torch.sigmoid(y_pred)>0.5).cpu().long()#.max(dim=1)[1]\n",
        "    n_correct = torch.eq(y_pred_indices, y_target).sum().item()\n",
        "    return n_correct / len(y_pred_indices) * 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsUZnFEbl7ut",
        "colab_type": "text"
      },
      "source": [
        "## Training Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BARlK1gjkCKP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#general utilities\n",
        "\n",
        "def set_seed_everywhere(seed, cuda):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if cuda:\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "def handle_dirs(dirpath):\n",
        "    if not os.path.exists(dirpath):\n",
        "        os.makedirs(dirpath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_v3EqzAkdwM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "09452c2f-0ec9-4562-83e7-d3e175171201"
      },
      "source": [
        "#setting\n",
        "args = Namespace(\n",
        "    # Data and Path information\n",
        "    frequency_cutoff=25,\n",
        "    model_state_file='model.pth',\n",
        "    review_csv='reviews_with_splits_lite.csv',\n",
        "    # review_csv='data/yelp/reviews_with_splits_full.csv',\n",
        "    save_dir='yelp_review/',\n",
        "    vectorizer_file='vectorizer.json',\n",
        "    # No Model hyper parameters\n",
        "    # Training hyper parameters\n",
        "    batch_size=128,\n",
        "    early_stopping_criteria=5,\n",
        "    learning_rate=0.001,\n",
        "    num_epochs=100,\n",
        "    seed=1337,\n",
        "    # Runtime options\n",
        "    catch_keyboard_interrupt=True,\n",
        "    cuda=True,\n",
        "    expand_filepaths_to_save_dir=True,\n",
        "    reload_from_files=False,\n",
        ")\n",
        "\n",
        "if args.expand_filepaths_to_save_dir:\n",
        "    args.vectorizer_file = os.path.join(args.save_dir,\n",
        "                                        args.vectorizer_file)\n",
        "\n",
        "    args.model_state_file = os.path.join(args.save_dir,\n",
        "                                         args.model_state_file)\n",
        "    \n",
        "    print(\"Expanded filepaths: \")\n",
        "    print(\"\\t{}\".format(args.vectorizer_file))\n",
        "    print(\"\\t{}\".format(args.model_state_file))\n",
        "    \n",
        "# Check CUDA\n",
        "if not torch.cuda.is_available():\n",
        "    args.cuda = False\n",
        "\n",
        "print(\"Using CUDA: {}\".format(args.cuda))\n",
        "\n",
        "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
        "\n",
        "# Set seed for reproducibility\n",
        "set_seed_everywhere(args.seed, args.cuda)\n",
        "\n",
        "# handle dirs\n",
        "handle_dirs(args.save_dir)"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Expanded filepaths: \n",
            "\tyelp_review/vectorizer.json\n",
            "\tyelp_review/model.pth\n",
            "Using CUDA: False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yrgerri4kmsz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a0ff9179-9947-477d-c944-6e41db355f89"
      },
      "source": [
        "#Initialization\n",
        "if args.reload_from_files:\n",
        "    # training from a checkpoint\n",
        "    print(\"Loading dataset and vectorizer\")\n",
        "    dataset = ReviewDataset.load_dataset_and_load_vectorizer(args.review_csv,\n",
        "                                                            args.vectorizer_file)\n",
        "else:\n",
        "    print(\"Loading dataset and creating vectorizer\")\n",
        "    # create dataset and vectorizer\n",
        "    dataset = ReviewDataset.load_dataset_and_make_vectorizer(args.review_csv)\n",
        "    dataset.save_vectorizer(args.vectorizer_file)    \n",
        "vectorizer = dataset.get_vectorizer()\n",
        "\n",
        "classifier = ReviewClassifier(num_features=len(vectorizer.review_vocab))"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading dataset and creating vectorizer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eU1OqNXaktmM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470,
          "referenced_widgets": [
            "418872eb46a94ef8a429fd872ffb9a6f",
            "0c6853a7ba344a40a2fb2f791cfb2135",
            "0e0184261fc54daba9212825585fd07c",
            "17db3148179348d5b7d481384ad6c81a",
            "1d30a1fdef974f04bd520e38a89a6942",
            "87354c46c0b3454693e7ee77f8901e5c",
            "8336f5ef3e554cadb54b1a0987384f71",
            "d9cab2e08851458c8bb706cd3e7fd9e6",
            "f2c09ea5341f48fb9b58c71b830aa353",
            "93efb731465c4e5ba64e337553efc119",
            "66b575da0248479db5c08096657639e4",
            "ed6ef05a4b4d48249254465a816aefba",
            "f459c742f6bd49648653ec6a3fc62191",
            "b3a3447c9a904c17a667759c599685d7",
            "e22887f69a8c47f8a45d71ecde709d23",
            "aca1b5af3dbe4291a1869b3b7e6b4578",
            "5769796678534953b52f264f60be8da2",
            "de7fc6f0a3124e19b26c7ae0ec35e2b7",
            "c16d180185684caa848c35599aed55cd",
            "e16d2e1e09524fd1a92615c63bed0833",
            "5da9e1df844b4b55a53379e8d89b09b2",
            "6c3f4fc1cc7049a9a715a65076521b64",
            "313023f86b5640408875adf351084899",
            "7c29ff0c2bab4193bdb6793dcafc4752"
          ]
        },
        "outputId": "101e444c-9f22-41c4-a323-33b5d6497548"
      },
      "source": [
        "#starting training\n",
        "classifier = classifier.to(args.device)\n",
        "\n",
        "\"\"\"the most appropriate loss function for binary classification is binary cross-entropy loss, and it is more numerically\n",
        "stable to pair the BCEWithLogitsLoss() function with a model that doesn’t\n",
        "apply the sigmoid function to the output than to pair the BCELoss() function\n",
        "with a model that does apply the sigmoid function to the output.\"\"\"\n",
        "\n",
        "loss_func = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(classifier.parameters(), lr=args.learning_rate)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
        "                                                 mode='min', factor=0.5,\n",
        "                                                 patience=1)\n",
        "\n",
        "train_state = make_train_state(args)\n",
        "\n",
        "epoch_bar = tqdm_notebook(desc='training routine', \n",
        "                          total=args.num_epochs,\n",
        "                          position=0)\n",
        "\n",
        "dataset.set_split('train')\n",
        "train_bar = tqdm_notebook(desc='split=train',\n",
        "                          total=dataset.get_num_batches(args.batch_size), \n",
        "                          position=1, \n",
        "                          leave=True)\n",
        "dataset.set_split('val')\n",
        "val_bar = tqdm_notebook(desc='split=val',\n",
        "                        total=dataset.get_num_batches(args.batch_size), \n",
        "                        position=1, \n",
        "                        leave=True)\n",
        "\n",
        "try:\n",
        "    for epoch_index in range(args.num_epochs):\n",
        "        train_state['epoch_index'] = epoch_index\n",
        "\n",
        "        # Iterate over training dataset\n",
        "\n",
        "        # setup: batch generator, set loss and acc to 0, set train mode on\n",
        "        dataset.set_split('train')\n",
        "        batch_generator = generate_batches(dataset, \n",
        "                                           batch_size=args.batch_size, \n",
        "                                           device=args.device)\n",
        "        running_loss = 0.0\n",
        "        running_acc = 0.0\n",
        "\n",
        "        #indicate the model is in training model\n",
        "        classifier.train()\n",
        "\n",
        "        for batch_index, batch_dict in enumerate(batch_generator):\n",
        "            # the training routine is these 5 steps:\n",
        "\n",
        "            # --------------------------------------\n",
        "            # step 1. zero the gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # step 2. compute the output\n",
        "            y_pred = classifier(x_in=batch_dict['x_data'].float())\n",
        "\n",
        "            # step 3. compute the loss\n",
        "            loss = loss_func(y_pred, batch_dict['y_target'].float())\n",
        "            loss_t = loss.item()\n",
        "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "\n",
        "            # step 4. use loss to produce gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # step 5. use optimizer to take gradient step\n",
        "            optimizer.step()\n",
        "            # -----------------------------------------\n",
        "            # compute the accuracy\n",
        "            acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
        "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "            # update bar\n",
        "            train_bar.set_postfix(loss=running_loss, \n",
        "                                  acc=running_acc, \n",
        "                                  epoch=epoch_index)\n",
        "            train_bar.update()\n",
        "\n",
        "        train_state['train_loss'].append(running_loss)\n",
        "        train_state['train_acc'].append(running_acc)\n",
        "\n",
        "        # Iterate over val dataset\n",
        "\n",
        "        # setup: batch generator, set loss and acc to 0; set eval mode on\n",
        "        dataset.set_split('val')\n",
        "        batch_generator = generate_batches(dataset, \n",
        "                                           batch_size=args.batch_size, \n",
        "                                           device=args.device)\n",
        "        running_loss = 0.\n",
        "        running_acc = 0.\n",
        "\n",
        "        #indicating the model is in evaluation mode, and parameters immutable and disable the dropout\n",
        "        #also disable computation of loss and gradient\n",
        "        \n",
        "        classifier.eval()\n",
        "\n",
        "        for batch_index, batch_dict in enumerate(batch_generator):\n",
        "\n",
        "            # compute the output\n",
        "            y_pred = classifier(x_in=batch_dict['x_data'].float())\n",
        "\n",
        "            # step 3. compute the loss\n",
        "            loss = loss_func(y_pred, batch_dict['y_target'].float())\n",
        "            loss_t = loss.item()\n",
        "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "\n",
        "            # compute the accuracy\n",
        "            acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
        "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "            \n",
        "            val_bar.set_postfix(loss=running_loss, \n",
        "                                acc=running_acc, \n",
        "                                epoch=epoch_index)\n",
        "            val_bar.update()\n",
        "\n",
        "        train_state['val_loss'].append(running_loss)\n",
        "        train_state['val_acc'].append(running_acc)\n",
        "\n",
        "        train_state = update_train_state(args=args, model=classifier,\n",
        "                                         train_state=train_state)\n",
        "\n",
        "        scheduler.step(train_state['val_loss'][-1])\n",
        "\n",
        "        train_bar.n = 0\n",
        "        val_bar.n = 0\n",
        "        epoch_bar.update()\n",
        "\n",
        "        if train_state['stop_early']:\n",
        "            break\n",
        "\n",
        "        train_bar.n = 0\n",
        "        val_bar.n = 0\n",
        "        epoch_bar.update()\n",
        "except KeyboardInterrupt:\n",
        "    print(\"Exiting loop\")"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "418872eb46a94ef8a429fd872ffb9a6f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='training routine', style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f2c09ea5341f48fb9b58c71b830aa353",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='split=train', max=306, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5769796678534953b52f264f60be8da2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='split=val', max=65, style=ProgressStyle(description_width='in…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-159-570030c307a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;31m# step 3. compute the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m             \u001b[0mloss_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss_t\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mrunning_loss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    599\u001b[0m                                                   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m                                                   \u001b[0mpos_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m                                                   reduction=self.reduction)\n\u001b[0m\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   2122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2123\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2124\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Target size ({}) must be the same as input size ({})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2126\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Target size (torch.Size([128])) must be the same as input size (torch.Size([1, 3]))"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pb89HqTDk0xQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compute the loss & accuracy on the test set using the best available model\n",
        "\n",
        "classifier.load_state_dict(torch.load(train_state['model_filename']))\n",
        "classifier = classifier.to(args.device)\n",
        "\n",
        "dataset.set_split('test')\n",
        "batch_generator = generate_batches(dataset, \n",
        "                                   batch_size=args.batch_size, \n",
        "                                   device=args.device)\n",
        "running_loss = 0.\n",
        "running_acc = 0.\n",
        "classifier.eval()\n",
        "\n",
        "for batch_index, batch_dict in enumerate(batch_generator):\n",
        "    # compute the output\n",
        "    y_pred = classifier(x_in=batch_dict['x_data'].float())\n",
        "\n",
        "    # compute the loss\n",
        "    loss = loss_func(y_pred, batch_dict['y_target'].float())\n",
        "    loss_t = loss.item()\n",
        "    running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "\n",
        "    # compute the accuracy\n",
        "    acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
        "    running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "train_state['test_loss'] = running_loss\n",
        "train_state['test_acc'] = running_acc\n",
        "\n",
        "print(\"Test loss: {:.3f}\".format(train_state['test_loss']))\n",
        "print(\"Test Accuracy: {:.2f}\".format(train_state['test_acc']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLh6-6Y8lNrs",
        "colab_type": "text"
      },
      "source": [
        "## Predicting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_n_5moq7lJXA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_rating(review, classifier, vectorizer, decision_threshold=0.5):\n",
        "    \"\"\"Predict the rating of a review\n",
        "    \n",
        "    Args:\n",
        "        review (str): the text of the review\n",
        "        classifier (ReviewClassifier): the trained model\n",
        "        vectorizer (ReviewVectorizer): the corresponding vectorizer\n",
        "        decision_threshold (float): The numerical boundary which separates the rating classes\n",
        "    \"\"\"\n",
        "    review = preprocess_text(review)\n",
        "    \n",
        "    vectorized_review = torch.tensor(vectorizer.vectorize(review))\n",
        "    result = classifier(vectorized_review.view(1, -1))\n",
        "    \n",
        "    probability_value = F.sigmoid(result).item()\n",
        "    index = 1\n",
        "    if probability_value < decision_threshold:\n",
        "        index = 0\n",
        "\n",
        "    return vectorizer.rating_vocab.lookup_index(index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1NWgdkUlMzV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_review = \"this is a pretty awesome book\"\n",
        "\n",
        "classifier = classifier.cpu()\n",
        "prediction = predict_rating(test_review, classifier, vectorizer, decision_threshold=0.5)\n",
        "print(\"{} -> {}\".format(test_review, prediction))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMRkthR8lTQq",
        "colab_type": "text"
      },
      "source": [
        "## Interpretability"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NETV00OtlXOh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier.fc1.weight.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gORTVvHXlaTJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Sort weights\n",
        "fc1_weights = classifier.fc1.weight.detach()[0]\n",
        "_, indices = torch.sort(fc1_weights, dim=0, descending=True)\n",
        "indices = indices.numpy().tolist()\n",
        "\n",
        "# Top 20 words\n",
        "print(\"Influential words in Positive Reviews:\")\n",
        "print(\"--------------------------------------\")\n",
        "for i in range(20):\n",
        "    print(vectorizer.review_vocab.lookup_index(indices[i]))\n",
        "    \n",
        "print(\"====\\n\\n\\n\")\n",
        "\n",
        "# Top 20 negative words\n",
        "print(\"Influential words in Negative Reviews:\")\n",
        "print(\"--------------------------------------\")\n",
        "indices.reverse()\n",
        "for i in range(20):\n",
        "    print(vectorizer.review_vocab.lookup_index(indices[i]))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}